# H.A.Y.D.A.R.

**H.A.Y.D.A.R.** stands for **"HayatÄ±n AkÄ±ÅŸÄ±na YÃ¶n Veren Dinamik AkÄ±llÄ± Rehber"**, a Turkish phrase meaning _"A Dynamic Smart Guide That Directs the Flow of Life."_  
Inspired by Iron Manâ€™s **J.A.R.V.I.S.**, this project aims to create a **fully local, character-rich voice assistant** that lives on your personal machine.

---

## ğŸ¯ Goals

- Voice-based interaction (speech-to-text + text-to-speech)
- Local LLM (starting with GPT-OSS-20B or OpenAI API fallback)
- Streamlit (or similar) UI for easy control and testing
- Persona system for humor, character, memory
- Offline-first architecture
- Command handling (print this, search that, turn on lights etc.)
- Modular and extensible codebase
- 3D-printed dummy bot control (long-term goal)

---

## ğŸ› ï¸ Tech Stack

- Python 3.10+
- Whisper / Whisper.cpp for STT
- Coqui TTS or Piper for TTS
- Streamlit UI (temporary frontend)
- GPT-based brain (OpenAI or open-weight LLM)
- Optional: MQTT / HomeAssistant / CUPS / Linux CLI integration

---

## ğŸš§ Project Status

> This project is under active development. First step: setting up voice input/output and basic conversation loop.

---

## ğŸ“„ License

This project is licensed under the MIT License â€” see the [LICENSE.md](./LICENSE.md) file for details.


# H.A.Y.D.A.R. V1 â€” Voice-to-GPT Personal Assistant

**H.A.Y.D.A.R.** (short for "Highly Adaptive Yet Dependable AI Reactor")  
Version 1 delivers a basic voice-to-AI interaction pipeline using open-source LLMs and speech-to-text tools.

---

## ğŸ§  What it can do (V1 Features)

- ğŸ™ï¸ Records your voice via microphone
- ğŸ“ Transcribes speech to Turkish text (using Whisper)
- ğŸ¤– Sends the text to a locally running GPT model (via Ollama)
- ğŸ’¬ Displays the response on screen
- â±ï¸ Measures and logs total GPT response time

---

## ğŸ“‚ How to Run (Quick Start)

> Requirements:
- Python 3.10+
- [ollama](https://ollama.com/) installed and model gpt-oss:20b downloaded
- ffmpeg, whisper, sounddevice, scipy installed

bash
pip install openai-whisper sounddevice scipy
ollama run gpt-oss:20b
python audio_input.py



## ğŸ› ï¸ Technologies Used

- OpenAI Whisper for speech-to-text

- Ollama to run LLMs locally

- sounddevice for audio recording

- scipy for WAV file output

### ğŸ”œ Whatâ€™s Next (Planned for V2)

    - ğŸ—£ï¸ TTS (Text-to-Speech) with a realistic Turkish male voice (e.g., JARVIS-like)

    - ğŸ­ Personality layer (custom responses like "Efendim?" and tone)

    - ğŸ§± Modular refactor and first UI shell
